{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adjacent-israel",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-capability",
   "metadata": {},
   "source": [
    "```bash\n",
    "├── data\n",
    "│   ├── out_data\n",
    "│   ├── rf_data\n",
    "│   ├── water_data\n",
    "│   ├── test_data_imp_0831.csv\n",
    "│   ├── train_data_imp_0831.csv\n",
    "├── out\n",
    "├── Imputaton-Submission.ipynb\n",
    "└── Project-Submission.ipynb\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-beatles",
   "metadata": {},
   "source": [
    "# OS\n",
    "- Ubuntu\n",
    "- Intel i9 10900\n",
    "- NVIDIA GeForce RTX 3080\n",
    "- Memory 64GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-floor",
   "metadata": {},
   "source": [
    "# 주의사항\n",
    "\n",
    "- 메모리 최소 30GB 이상 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "innovative-dublin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from scipy import interpolate\n",
    "\n",
    "#visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor , AdaBoostRegressor, StackingRegressor, BaggingRegressor, VotingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.base import clone\n",
    "\n",
    "import random\n",
    "import os\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ANN module\n",
    "import torch\n",
    "from torch import nn, optim                           # torch 에서 제공하는 신경망 기술, 손실함수, 최적화를 할 수 있는 함수들을 불러온다.\n",
    "from torch.utils.data import DataLoader, Dataset      # 데이터를 모델에 사용할 수 있게 정리해주는 라이브러리.\n",
    "import torch.nn.functional as F                       # torch 내의 세부적인 기능을 불러옴.\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_freq(x, number):\n",
    "    s_fft = np.fft.fft(x) # 추후 IFFT를 위해 abs를 취하지 않은 값을 저장한다.\n",
    "    amplitude = abs(s_fft)*(2/len(s_fft))\n",
    "    frequency = np.fft.fftfreq(len(s_fft))\n",
    "    fft_freq = frequency.copy()    \n",
    "    peak_index = amplitude[:int(len(amplitude)/2)].argsort()[-number:]\n",
    "    peak_freq = fft_freq[peak_index]\n",
    "    \n",
    "    return peak_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "challenging-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_amp(x, number):\n",
    "    s_fft = np.fft.fft(x) # 추후 IFFT를 위해 abs를 취하지 않은 값을 저장한다.\n",
    "    amplitude = abs(s_fft)*(2/len(s_fft))\n",
    "    frequency = np.fft.fftfreq(len(s_fft))\n",
    "    fft_freq = frequency.copy()    \n",
    "    peak_index = amplitude[:int(len(amplitude)/2)].argsort()[-number:]\n",
    "    peak_amp = amplitude[peak_index]\n",
    "    \n",
    "    return peak_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "superior-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "knowing-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train_data_imp_0831.csv\")\n",
    "test_data = pd.read_csv(\"./data/test_data_imp_0831.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungry-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = ['wl_1019630' ,  'wl_1018683'  ,  'wl_1018680'  ,  'wl_1018662']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "crucial-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['month'] = train_data['ymdhm'].apply(lambda x: np.int(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M').strftime('%m')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attended-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['month'] = test_data['ymdhm'].apply(lambda x: np.int(datetime.datetime.strptime(x, '%Y-%m-%d %H:%M').strftime('%m')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-rabbit",
   "metadata": {},
   "source": [
    "## 변수 선택 및 최적 lag 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cutting-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, data, lag, y_column, x_column, shift):\n",
    "        self.data = data.copy()\n",
    "        self.lag = lag\n",
    "        self.y_cols = y_column\n",
    "        self.x_cols = x_column\n",
    "        self.shift = shift\n",
    "        \n",
    "    def train(self, estimator, scale, square):\n",
    "        self.square = square\n",
    "\n",
    "        self.scale = scale\n",
    "        if self.scale == True:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(self.data[self.x_cols])\n",
    "            self.data[self.x_cols] = self.scaler.transform(self.data[self.x_cols])\n",
    "\n",
    "            \n",
    "        col_list = ['month']\n",
    "        for x_col in self.x_cols:\n",
    "            self.data[x_col+'_percentage_lag1']= (self.data[x_col].shift(1) - self.data[x_col].shift(2))/(self.data[x_col].shift(2)+1e-6)\n",
    "            col_list.append(x_col+'_percentage_lag1')\n",
    "            self.data[x_col+'_percentage_lag2']= (self.data[x_col].shift(2) - self.data[x_col].shift(3))/(self.data[x_col].shift(3)+1e-6)\n",
    "            col_list.append(x_col+'_percentage_lag2')\n",
    "        \n",
    "#         print(self.data.columns)\n",
    "        \n",
    "        for x_col in self.x_cols:\n",
    "            for s in range(1, self.lag+1):\n",
    "                self.data[x_col+'_lag_'+str(s)] = self.data[x_col].shift(s)\n",
    "                self.data['year_lag_'+str(s)] = self.data['year'].shift(s)\n",
    "                col_list.append(x_col+'_lag_'+str(s))\n",
    "#         print(col_list)   \n",
    "#         print(self.data.columns)\n",
    "        Train_data = self.data[self.data['year'] == self.data['year_lag_'+str(s)]]\n",
    "        Train_data = Train_data[['ymdhm', 'year']+col_list + self.y_cols].dropna()\n",
    "        Train_data = Train_data.reset_index(drop=True)\n",
    "\n",
    "        for x in tqdm(self.x_cols):\n",
    "\n",
    "            ts= Train_data.filter(regex=x+'_lag')\n",
    "#             print(ts.columns)\n",
    "\n",
    "            number = np.int(self.lag/3)\n",
    "            fft_fr = ts.apply(lambda x: fft_freq(np.array(x), number)  ,axis=1)\n",
    "            fft_mp = ts.apply(lambda x: fft_amp(np.array(x), number)  ,axis=1)\n",
    "            \n",
    "            numbers = range(number)\n",
    "            for num in numbers:\n",
    "                Train_data['freq_'+ x + '_'+str(num)]= fft_fr.apply(lambda x: x[num])\n",
    "                Train_data['amp_'+ x + '_'+str(num)]= fft_mp.apply(lambda x: x[num])\n",
    "\n",
    "                col_list.append('freq_'+ x + '_' +str(num))\n",
    "                col_list.append('amp_'+ x + '_' +str(num))\n",
    "        #     print(ts.columns)\n",
    "            square_columns = ts.columns\n",
    "            for sc in square_columns:\n",
    "                Train_data['square_'+ sc] = Train_data[sc] ** 2\n",
    "                col_list.append('square_'+ sc )\n",
    "\n",
    "#         print(Train_data.columns)\n",
    "        \n",
    "        train_X = Train_data[col_list]\n",
    "        train_Y = Train_data[self.y_cols]\n",
    "        \n",
    "        print(\"X shape: \", train_X.shape, \"Y shape: \", train_Y.shape)\n",
    "        \n",
    "        self.model_list = []\n",
    "        kf = KFold(n_splits=3, shuffle = True, random_state = 1234)\n",
    "        \n",
    "        mse_list = []\n",
    "        for train_index, val_index in kf.split(train_X.index):\n",
    "            x_train = train_X.iloc[train_index]\n",
    "            x_valid = train_X.iloc[val_index]\n",
    "            y_train = train_Y.iloc[train_index]\n",
    "            y_valid = train_Y.iloc[val_index]\n",
    "            \n",
    "            models = clone(estimator)\n",
    "            \n",
    "            models.fit(x_train, y_train)\n",
    "            preds = models.predict(x_valid)\n",
    "            mse = mean_squared_error(np.array(y_valid),preds)**0.5\n",
    "            mse_list.append(mse)\n",
    "            \n",
    "            self.model_list.append(models) \n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        return np.array(mse_list).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "front-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RegressorChain( LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vanilla-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_data.columns\n",
    "x_columns = list(cols.drop(['ymdhm', 'time', 'year', 'wl_1018662', 'fw_1018662', 'wl_1018680', 'wl_1018683', 'fw_1018683', 'wl_1019630', 'fw_1019630', 'fw_out_1018680', 'fw_out_1019675', 'wl_out_1018658', 'fw_out_1018658', 'month']))\n",
    "drop_cols = x_columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pharmaceutical-tyler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop cols:  ['ymdhm', 'year', 'time', 'wl_1018662', 'fw_1018662', 'wl_1018680', 'wl_1018683', 'fw_1018683', 'wl_1019630', 'fw_1019630', 'fw_out_1018680', 'fw_out_1019675', 'wl_out_1018658', 'fw_out_1018658', 'month', 'swl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:37<00:00, 13.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (267853, 851) Y shape:  (267853, 4)\n",
      "lag  12 :  1.1265182466735775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:36<00:00, 13.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (267703, 1251) Y shape:  (267703, 4)\n",
      "lag  18 :  1.1240537046229346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:41<00:00, 13.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (267553, 1651) Y shape:  (267553, 4)\n",
      "lag  24 :  1.139241349321898\n",
      "best lag:  18 MSE:  1.1240537046229346\n",
      "drop!\n",
      "drop cols:  ['ymdhm', 'year', 'time', 'wl_1018662', 'fw_1018662', 'wl_1018680', 'wl_1018683', 'fw_1018683', 'wl_1019630', 'fw_1019630', 'fw_out_1018680', 'fw_out_1019675', 'wl_out_1018658', 'fw_out_1018658', 'month', 'swl', 'inf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:18<06:56, 18.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-42718842ef3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# model.Imputation(shift = 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mMSE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquare\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lag \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmse_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5eb8f05b1e18>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, estimator, scale, square)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mfft_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mfft_mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_amp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5eb8f05b1e18>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mfft_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mfft_mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_amp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6283c1067ccf>\u001b[0m in \u001b[0;36mfft_freq\u001b[0;34m(x, number)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ms_fft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 추후 IFFT를 위해 abs를 취하지 않은 값을 저장한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mamplitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfft_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpeak_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamplitude\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/fft/helper.py\u001b[0m in \u001b[0;36mfftfreq\u001b[0;34m(n, d)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_mse = 10\n",
    "init_drop = ['ymdhm', 'year', 'time', 'wl_1018662', 'fw_1018662', 'wl_1018680', 'wl_1018683', 'fw_1018683', 'wl_1019630', 'fw_1019630', 'fw_out_1018680', 'fw_out_1019675', 'wl_out_1018658', 'fw_out_1018658', 'month']\n",
    "start_lag = 12\n",
    "end_lag = 24\n",
    "lag_list = list(range(start_lag,end_lag+1, 6))\n",
    "for i in range(len(drop_cols)):\n",
    "    \n",
    "    x_columns = list(cols.drop(init_drop + [drop_cols[i]]))\n",
    "    print(\"drop cols: \", init_drop + [drop_cols[i]])\n",
    "    model_list = []\n",
    "    mse_list = []\n",
    "    for l in lag_list:    \n",
    "        model = Model(train_data, l, y_columns, x_columns, shift = 0)\n",
    "        # model.Imputation(shift = 3)\n",
    "        MSE=model.train(estimator, scale = True, square =True)\n",
    "        print(\"lag \", l, \": \", MSE)\n",
    "        mse_list.append(MSE)\n",
    "        model_list.append(model)\n",
    "    print(\"best lag: \", lag_list[np.argmin(mse_list)], \"MSE: \", mse_list[np.argmin(mse_list)])\n",
    "    \n",
    "    if best_mse > mse_list[np.argmin(mse_list)]:\n",
    "        best_mse = mse_list[np.argmin(mse_list)]\n",
    "        best_model = model_list[np.argmin(mse_list)]\n",
    "        init_drop = init_drop + [drop_cols[i]]\n",
    "        best_lag = lag_list[np.argmin(mse_list)]\n",
    "        print(\"drop!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pharmaceutical-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inf',\n",
       " 'sfw',\n",
       " 'ecpc',\n",
       " 'tototf',\n",
       " 'tide_level',\n",
       " 'rf_10184100',\n",
       " 'rf_10184110',\n",
       " 'rf_10184140',\n",
       " 'rf_out_0194010',\n",
       " 'fw_out_1018610',\n",
       " 'wl_out_1018610',\n",
       " 'fw_out_1018640',\n",
       " 'wl_out_1018640',\n",
       " 'fw_out_1018662',\n",
       " 'wl_out_1018662',\n",
       " 'fw_out_1018675',\n",
       " 'wl_out_1018675',\n",
       " 'wl_out_1018680',\n",
       " 'fw_out_1018683',\n",
       " 'wl_out_1018683',\n",
       " 'fw_out_1018697',\n",
       " 'wl_out_1018697',\n",
       " 'fw_out_1019630',\n",
       " 'wl_out_1019630',\n",
       " 'wl_out_1019675']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = list(cols.drop(init_drop))\n",
    "x_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minute-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "southeast-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ymdhm', 'swl', 'inf', 'sfw', 'ecpc', 'tototf', 'tide_level',\n",
      "       'wl_1018662', 'fw_1018662', 'wl_1018680',\n",
      "       ...\n",
      "       'fw_out_1018697_max', 'fw_out_1018697_min', 'wl_out_1018697_max',\n",
      "       'wl_out_1018697_min', 'fw_out_1019630_max', 'fw_out_1019630_min',\n",
      "       'wl_out_1019630_max', 'wl_out_1019630_min', 'wl_out_1019675_max',\n",
      "       'wl_out_1019675_min'],\n",
      "      dtype='object', length=341)\n",
      "Index(['ymdhm', 'swl', 'inf', 'sfw', 'ecpc', 'tototf', 'tide_level',\n",
      "       'wl_1018662', 'fw_1018662', 'wl_1018680',\n",
      "       ...\n",
      "       'wl_out_1019675_lag_9', 'wl_out_1019675_lag_10',\n",
      "       'wl_out_1019675_lag_11', 'wl_out_1019675_lag_12',\n",
      "       'wl_out_1019675_lag_13', 'wl_out_1019675_lag_14',\n",
      "       'wl_out_1019675_lag_15', 'wl_out_1019675_lag_16',\n",
      "       'wl_out_1019675_lag_17', 'wl_out_1019675_lag_18'],\n",
      "      dtype='object', length=809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9e51eb3fca9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_lag\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfft_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mfft_mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_amp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7550\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7551\u001b[0m         )\n\u001b[0;32m-> 7552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-9e51eb3fca9c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_lag\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mfft_fr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mfft_mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfft_amp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d6a9696232b4>\u001b[0m in \u001b[0;36mfft_amp\u001b[0;34m(x, number)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ms_fft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 추후 IFFT를 위해 abs를 취하지 않은 값을 저장한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mamplitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfft_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpeak_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamplitude\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/fft/helper.py\u001b[0m in \u001b[0;36mfftfreq\u001b[0;34m(n, d)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tt = train_data.copy()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(tt[x_columns])\n",
    "tt[x_columns] = scaler.transform(tt[x_columns])\n",
    "col_list = ['month']\n",
    "for x_col in x_columns:\n",
    "    tt[x_col+'_percentage_lag1_diff1']= (tt[x_col].shift(1) - tt[x_col].shift(2))/(tt[x_col].shift(2)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag1_diff1')\n",
    "    tt[x_col+'_percentage_lag1_diff2']= (tt[x_col].shift(1) - tt[x_col].shift(3))/(tt[x_col].shift(3)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag1_diff2')\n",
    "    tt[x_col+'_percentage_lag2']= (tt[x_col].shift(2) - tt[x_col].shift(3))/(tt[x_col].shift(3)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag2')\n",
    "    tt[x_col+'_percentage_lag3']= (tt[x_col].shift(3) - tt[x_col].shift(4))/(tt[x_col].shift(4)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag3')\n",
    "\n",
    "for x_col in x_columns:\n",
    "    tt[x_col+'_diff1']= (tt[x_col].shift(1) - tt[x_col].shift(2))\n",
    "    col_list.append(x_col+'_diff1')\n",
    "    tt[x_col+'_diff2']= (tt[x_col].shift(1) - tt[x_col].shift(3))\n",
    "    col_list.append(x_col+'_diff2')\n",
    "    \n",
    "for x_col in x_columns:\n",
    "    tt[x_col+'diff6']= tt[x_col].shift(1) - tt[x_col].shift(7)\n",
    "    col_list.append(x_col+'diff6')\n",
    "    tt[x_col+'diff12']= tt[x_col].shift(1) - tt[x_col].shift(13)\n",
    "    col_list.append(x_col+'diff12')   \n",
    "    \n",
    "for x_col in x_columns:\n",
    "    tt[x_col+'_percentage_diff6']= (tt[x_col].shift(1) - tt[x_col].shift(7))/(tt[x_col].shift(7)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_diff6')\n",
    "    tt[x_col+'_percentage_diff12']= (tt[x_col].shift(1) - tt[x_col].shift(13))/(tt[x_col].shift(13)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_diff12')\n",
    "\n",
    "\n",
    "    \n",
    "for x_col in x_columns:\n",
    "    tt[x_col+'_max']= np.max(np.array([tt[x_col].shift(i) for i in range(1, 7)]), axis =0)\n",
    "    col_list.append(x_col+'_max')\n",
    "    tt[x_col+'_min']= np.min(np.array([tt[x_col].shift(i) for i in range(1, 7)]), axis =0)\n",
    "    col_list.append(x_col+'_min')\n",
    "    \n",
    "print(tt.columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for x_col in x_columns:\n",
    "    for s in range(1, best_lag+1):\n",
    "        tt[x_col+'_lag_'+str(s)] = tt[x_col].shift(s)\n",
    "        tt['year_lag_'+str(s)] = tt['year'].shift(s)\n",
    "        col_list.append(x_col+'_lag_'+str(s))\n",
    "#         print(col_list)   \n",
    "print(tt.columns)\n",
    "tt = tt[tt['year'] == tt['year_lag_'+str(s)]]\n",
    "tt = tt[['ymdhm', 'year']+col_list + y_columns].dropna()\n",
    "tt = tt.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "for x in tqdm(x_columns):\n",
    "    ts= tt.filter(regex=x+'_lag')\n",
    "    number = np.int(best_lag/2)\n",
    "    fft_fr = ts.apply(lambda x: fft_freq(np.array(x), number)  ,axis=1)\n",
    "    fft_mp = ts.apply(lambda x: fft_amp(np.array(x), number)  ,axis=1)\n",
    "\n",
    "    numbers = range(number)\n",
    "    for num in numbers:\n",
    "        tt['freq_'+ x + '_'+str(num)]= fft_fr.apply(lambda x: x[num])\n",
    "        tt['amp_'+ x + '_'+str(num)]= fft_mp.apply(lambda x: x[num])\n",
    "\n",
    "        col_list.append('freq_'+ x + '_' +str(num))\n",
    "        col_list.append('amp_'+ x + '_' +str(num))\n",
    "#     print(ts.columns)\n",
    "    square_columns = ts.columns\n",
    "    for sc in square_columns:\n",
    "        tt['square_'+ sc] = tt[sc] ** 2\n",
    "        col_list.append('square_'+ sc )\n",
    "        \n",
    "    root_columns = ts.columns\n",
    "    for rc in root_columns:\n",
    "        tt['root_'+ rc] = np.abs(tt[rc]) ** 0.5\n",
    "        col_list.append('root_'+ rc )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = tt[col_list]\n",
    "train_Y = tt[y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-violin",
   "metadata": {},
   "source": [
    "## 모형 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state = 1234)\n",
    "for train_index, val_index in kf.split(train_X.index):\n",
    "    x_train = train_X.iloc[train_index]\n",
    "    x_valid = train_X.iloc[val_index]\n",
    "    y_train = train_Y.iloc[train_index]\n",
    "    y_valid = train_Y.iloc[val_index]\n",
    "    models =  [RegressorChain(LGBMRegressor(n_estimators=5000)),\n",
    "               RegressorChain(LinearRegression())]\n",
    "\n",
    "\n",
    "\n",
    "    for k in range(len(models)):\n",
    "        models[k].fit(x_train, y_train)\n",
    "    preds = models[0].predict(x_valid)\n",
    "    for k in range(1,len(models)):\n",
    "        preds += models[k].predict(x_valid).reshape(-1,4)\n",
    "    preds = preds/(k+1)\n",
    "    print(\"MSE: \", mean_squared_error(np.array(y_valid),preds)**0.5)\n",
    "    for i in range(4):\n",
    "        print(mean_squared_error(np.array(y_valid)[:,i], preds[:,i])**0.5)\n",
    "        plt.scatter(np.array(y_valid)[:,i], preds[:,i])\n",
    "        plt.show()\n",
    "    \n",
    "    model_list.append(models)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "mse_list = []\n",
    "for train_index, val_index in kf.split(train_X.index):    \n",
    "    x_valid = train_X.iloc[val_index]\n",
    "    y_valid = train_Y.iloc[val_index]\n",
    "    models = model_list[cnt]\n",
    "    mses = []\n",
    "    for k in range(len(models)):\n",
    "        preds = models[k].predict(x_valid)\n",
    "        mse = [mean_squared_error(np.array(y_valid)[:,i], preds[:,i])**0.5 for i in range(4)]\n",
    "        print(models[k], mse)\n",
    "        mse = [1/mean_squared_error(np.array(y_valid)[:,i], preds[:,i])**0.5 for i in range(4)]\n",
    "        mses.append(mse)\n",
    "    mse_list.append(mses)\n",
    "    cnt += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = pd.concat([train_data.iloc[-(best_lag):], test_data])\n",
    "te[x_columns] = scaler.transform(te[x_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['month']\n",
    "\n",
    "for x_col in x_columns:\n",
    "    te[x_col+'_percentage_lag1_diff1']= (te[x_col].shift(1) - te[x_col].shift(2))/(te[x_col].shift(2)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag1_diff1')\n",
    "    te[x_col+'_percentage_lag1_diff2']= (te[x_col].shift(1) - te[x_col].shift(3))/(te[x_col].shift(3)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag1_diff2')\n",
    "    te[x_col+'_percentage_lag2']= (te[x_col].shift(2) - te[x_col].shift(3))/(te[x_col].shift(3)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag2')\n",
    "    te[x_col+'_percentage_lag3']= (te[x_col].shift(3) - te[x_col].shift(4))/(te[x_col].shift(4)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_lag3')\n",
    "\n",
    "for x_col in x_columns:\n",
    "    te[x_col+'_diff1']= (te[x_col].shift(1) - te[x_col].shift(2))\n",
    "    col_list.append(x_col+'_diff1')\n",
    "    te[x_col+'_diff2']= (te[x_col].shift(1) - te[x_col].shift(3))\n",
    "    col_list.append(x_col+'_diff2')\n",
    "    \n",
    "for x_col in x_columns:\n",
    "    te[x_col+'diff6']= te[x_col].shift(1) - te[x_col].shift(7)\n",
    "    col_list.append(x_col+'diff6')\n",
    "    te[x_col+'diff12']= te[x_col].shift(1) - te[x_col].shift(13)\n",
    "    col_list.append(x_col+'diff12')   \n",
    "    \n",
    "for x_col in x_columns:\n",
    "    te[x_col+'_percentage_diff6']= (te[x_col].shift(1) - te[x_col].shift(7))/(te[x_col].shift(7)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_diff6')\n",
    "    te[x_col+'_percentage_diff12']= (te[x_col].shift(1) - te[x_col].shift(13))/(te[x_col].shift(13)+1e-6)\n",
    "    col_list.append(x_col+'_percentage_diff12')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "for x_col in x_columns:\n",
    "    te[x_col+'_max']= np.max(np.array([te[x_col].shift(i) for i in range(1, 7)]), axis =0)\n",
    "    col_list.append(x_col+'_max')\n",
    "    te[x_col+'_min']= np.min(np.array([te[x_col].shift(i) for i in range(1, 7)]), axis =0)\n",
    "    col_list.append(x_col+'_min')\n",
    "    \n",
    "print(te.columns)\n",
    "\n",
    "for x_col in x_columns:\n",
    "    for s in range(1, best_lag+1):\n",
    "        te[x_col+'_lag_'+str(s)] = te[x_col].shift(s)\n",
    "        te['year_lag_'+str(s)] = te['year'].shift(s)\n",
    "        col_list.append(x_col+'_lag_'+str(s))\n",
    "#         print(col_list)   \n",
    "print(te.columns)\n",
    "te = te[te['year'] == te['year_lag_'+str(s)]]\n",
    "te = te[['ymdhm', 'year']+col_list + y_columns].dropna()\n",
    "te = te.reset_index(drop=True)\n",
    "\n",
    "\n",
    "for x in tqdm(x_columns):\n",
    "\n",
    "    ts= te.filter(regex=x+'_lag')\n",
    "    number = np.int(best_lag/2)\n",
    "    fft_fr = ts.apply(lambda x: fft_freq(np.array(x), number)  ,axis=1)\n",
    "    fft_mp = ts.apply(lambda x: fft_amp(np.array(x), number)  ,axis=1)\n",
    "\n",
    "    numbers = range(number)\n",
    "    for num in numbers:\n",
    "        te['freq_'+ x + '_'+str(num)]= fft_fr.apply(lambda x: x[num])\n",
    "        te['amp_'+ x + '_'+str(num)]= fft_mp.apply(lambda x: x[num])\n",
    "\n",
    "        col_list.append('freq_'+ x + '_' +str(num))\n",
    "        col_list.append('amp_'+ x + '_' +str(num))\n",
    "#     print(ts.columns)\n",
    "    square_columns = ts.columns\n",
    "    print(square_columns)\n",
    "    for sc in square_columns:\n",
    "        te['square_'+ sc] = te[sc] ** 2\n",
    "        col_list.append('square_'+ sc )\n",
    "        \n",
    "    root_columns = ts.columns\n",
    "    for rc in root_columns:\n",
    "        te['root_'+ rc] = np.abs(te[rc]) ** 0.5\n",
    "        col_list.append('root_'+ rc )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_columns = [ 'wl_1019630' ,  'wl_1018683'  ,  'wl_1018680'  ,  'wl_1018662']\n",
    "test = te[col_list+y_columns].dropna()\n",
    "test_X = test[col_list]\n",
    "test_Y = test[y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_list = []\n",
    "for i in range(len(model_list)):\n",
    "    models = model_list[i]\n",
    "    preds_test = models[0].predict(test_X)\n",
    "    for k in range(1,len(models)):\n",
    "        preds_test += models[k].predict(test_X).reshape(-1,4)\n",
    "    preds_test = preds_test/(k+1)  \n",
    "    preds_list.append(preds_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = np.array(preds_list).mean(0)\n",
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit[y_columns] = preds_1\n",
    "submit.to_csv('./out/submit_ensemble_0902.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = np.array(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5): # fold\n",
    "    for k in range(4): # Y\n",
    "        mm = np.array(mse_list)[i,:,:].sum(0)\n",
    "        weight_list[i,:,k] = weight_list[i,:,k]/mm[k]\n",
    "weights = weight_list.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_list = []\n",
    "for i in range(len(model_list)):\n",
    "    models = model_list[i]\n",
    "    preds_test = models[0].predict(test_X) * weights[0,:]\n",
    "    for j in range(1, len(models)):\n",
    "        preds_test += models[j].predict(test_X) * weights[j,:]\n",
    "    \n",
    "    preds_list.append(preds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = np.array(preds_list).mean(0)\n",
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit[y_columns] = preds_2\n",
    "submit.to_csv('./out/submit_ensemble_0902 (1).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./data/sample_submission.csv')\n",
    "submit[y_columns] = (preds_1+preds_2)/2\n",
    "submit.to_csv('./out/submit_ensemble_0902_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-value",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-boating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-characterization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-mouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-trail",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-physiology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
